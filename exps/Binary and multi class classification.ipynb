{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper Name: Feature requests-based recommendation of software refactorings\n",
    "#### Authors: Ally S. Nyamawe 路 Hui Liu 路 Nan Niu 路 Qasim Umer 路 Zhendong Niu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "#### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kritya/.pyenv/versions/3.7.5/lib/python3.7/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset laoded.....\n",
      "==========>\n",
      "dataset saved.....\n",
      "==========>\n",
      "[' anoth blueprint sampl contribut day test blueprint mbean gener complex blueprint sampl sampl user learn defin nest compon blueprint xml run sampl besid osgi framework bundl requir coreopt mavenbundl groupid org apach felix artifactid org apach felix configadmin versionasinproject coreopt mavenbundl groupid org apach felix artifactid org apach felix eventadmin versionasinproject coreopt mavenbundl groupid org ops4j pax log artifactid pax log api versionasinproject coreopt mavenbundl groupid org ops4j pax log artifactid pax log servic versionasinproject coreopt mavenbundl groupid org apach ari blueprint artifactid org apach ari blueprint versionasinproject coreopt mavenbundl groupid org apach ari artifactid org apach ari util coreopt mavenbundl groupid org apach ari jmx artifactid ari jmx blueprint versionasinproject', 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    f = open('/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/dataset/final_dataset.pickle', 'rb')\n",
    "    dataset = pickle.load(f)\n",
    "    f.close()\n",
    "    print(\"dataset laoded.....\")\n",
    "    print('==========>')\n",
    "\n",
    "\n",
    "    binary_class_dataset = []\n",
    "    for index in range(len(dataset)):\n",
    "        task = []\n",
    "        task.append(dataset[index][0])\n",
    "        if str(dataset[index][1][0]).strip() == 'none':\n",
    "            ref = 0\n",
    "        else:\n",
    "            ref = 1\n",
    "        task.append(ref)\n",
    "\n",
    "        binary_class_dataset.append(task)\n",
    "\n",
    "    f = open('/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/dataset/binary_class_dataset.pickle', 'wb')\n",
    "    pickle.dump(binary_class_dataset,f)\n",
    "    f.close()\n",
    "    print(\"dataset saved.....\")\n",
    "    print('==========>')\n",
    "    \n",
    "    \n",
    "    print(binary_class_dataset[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "#### Feature words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' anoth blueprint sampl contribut day test blueprint mbean gener complex blueprint sampl sampl user learn defin nest compon blueprint xml run sampl besid osgi framework bundl requir coreopt mavenbundl groupid org apach felix artifactid org apach felix configadmin versionasinproject coreopt mavenbundl groupid org apach felix artifactid org apach felix eventadmin versionasinproject coreopt mavenbundl groupid org ops4j pax log artifactid pax log api versionasinproject coreopt mavenbundl groupid org ops4j pax log artifactid pax log servic versionasinproject coreopt mavenbundl groupid org apach ari blueprint artifactid org apach ari blueprint versionasinproject coreopt mavenbundl groupid org apach ari artifactid org apach ari util coreopt mavenbundl groupid org apach ari jmx artifactid ari jmx blueprint versionasinproject', 0]\n",
      "tasks loaded.....\n",
      "all_phrases_without_freq saved......\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from collections import Counter\n",
    "import string\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text)\n",
    "    text.lower();\n",
    "    # Get the difference of all ASCII characters from the set of printable characters\n",
    "    nonprintable = set([chr(i) for i in range(128)]).difference(string.printable)\n",
    "    # Use translate to remove all non-printable characters\n",
    "    return text.translate({ord(character): None for character in nonprintable})\n",
    "\n",
    "def tokenization(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def pos_tagging(text):\n",
    "\n",
    "    return pos_tag(text)\n",
    "\n",
    "def lemmatization(pos_tags):\n",
    "    adjective_tags = ['JJ', 'JJR', 'JJS']\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = []\n",
    "    for word in pos_tags:\n",
    "        if word[1] in adjective_tags:\n",
    "            lemmatized_text.append(str(wordnet_lemmatizer.lemmatize(word[0], pos=\"a\")))\n",
    "        else:\n",
    "            lemmatized_text.append(str(wordnet_lemmatizer.lemmatize(word[0])))  # default POS = noun\n",
    "    return lemmatized_text\n",
    "\n",
    "def stop_word_removal(pos_tags_lem, lem_text):\n",
    "    stopwords = []\n",
    "\n",
    "    wanted_POS = ['NN', 'NNS', 'NNP', 'NNPS', 'JJ', 'JJR', 'JJS', 'VBG', 'FW']\n",
    "\n",
    "    for word in pos_tags_lem:\n",
    "        if word[1] not in wanted_POS:\n",
    "            stopwords.append(word[0])\n",
    "\n",
    "    punctuations = list(str(string.punctuation))\n",
    "\n",
    "    stopwords = stopwords + punctuations\n",
    "\n",
    "    stopword_file = open(\"./dataset/long_stopwords.txt\", \"r\")\n",
    "    # Source = https://www.ranks.nl/stopwords\n",
    "\n",
    "    lots_of_stopwords = []\n",
    "\n",
    "    for line in stopword_file.readlines():\n",
    "        lots_of_stopwords.append(str(line.strip()))\n",
    "\n",
    "    stopwords_plus = []\n",
    "    stopwords_plus = stopwords + lots_of_stopwords\n",
    "    stopwords_plus = set(stopwords_plus)\n",
    "\n",
    "    processed_text = []\n",
    "    for word in lem_text:\n",
    "        if word not in stopwords_plus:\n",
    "            processed_text.append(word)\n",
    "\n",
    "    return processed_text, stopwords_plus\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    load = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/dataset/binary_class_dataset.pickle\", \"rb\")\n",
    "    tasks = pickle.load(load)\n",
    "    load.close()\n",
    "    print(tasks[0])\n",
    "    print(\"tasks loaded.....\")\n",
    "\n",
    "    preprocessed_tasks = []\n",
    "\n",
    "    all_words = []\n",
    "    freq_words_without_freq = []\n",
    "\n",
    "    for index in range(len(tasks)):\n",
    "\n",
    "        # without preprocessing\n",
    "        old_task = tasks[index]\n",
    "        text = tasks[index][0].lower()\n",
    "        cleaned_text = clean_text(text)\n",
    "        words = re.findall(r'\\w+', cleaned_text)\n",
    "\n",
    "               # without preprocessing\n",
    "        for item in words:\n",
    "\n",
    "            all_words.append(item)\n",
    "\n",
    "\n",
    "    counts = Counter(all_words).most_common(5000)\n",
    "\n",
    "    for index in range(len(counts)):\n",
    "        freq_words_without_freq.append(counts[index][0])\n",
    "\n",
    "\n",
    "    file = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/dataset/freq_words_without_preprocessing.pickle\", \"wb\")\n",
    "    pickle.dump(freq_words_without_freq, file)\n",
    "    file.close()\n",
    "    print(\"all_phrases_without_freq saved......\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "#### Feature sets generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features of length  5000  is loaded.....\n",
      "1336 testing files loaded.....\n",
      "testing featuresets saved.....\n",
      "===============>\n",
      "1200 training files loaded.....\n",
      "training featuresets 1 saved.....\n",
      "===============>\n",
      "1200 training files loaded.....\n",
      "training featuresets 2 saved.....\n",
      "===============>\n",
      "1200 training files loaded.....\n",
      "training featuresets 3 saved.....\n",
      "===============>\n",
      "1200 training files loaded.....\n",
      "training featuresets 4 saved.....\n",
      "===============>\n",
      "1200 training files loaded.....\n",
      "training featuresets 5 saved.....\n",
      "===============>\n",
      "1200 training files loaded.....\n",
      "training featuresets 6 saved.....\n",
      "===============>\n",
      "1200 training files loaded.....\n",
      "training featuresets 7 saved.....\n",
      "===============>\n",
      "1200 training files loaded.....\n",
      "training featuresets 8 saved.....\n",
      "===============>\n",
      "1200 training files loaded.....\n",
      "training featuresets 9 saved.....\n",
      "===============>\n",
      "1228 training files loaded.....\n",
      "training featuresets 10 saved.....\n",
      "===============>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "def load_dataset():\n",
    "    file = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/dataset/shuffle_dataset.pickle\", \"rb\")\n",
    "    dataset = pickle.load(file)\n",
    "    file.close()\n",
    "    print(\"dataset of length \" , len(dataset) , \" is loaded.....\")\n",
    "    return dataset\n",
    "\n",
    "def load_features():\n",
    "    # file = open(\"./dataset/features.pickle\", \"rb\")\n",
    "    file = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/dataset/features_without_pp.pickle\", \"rb\")\n",
    "    features = pickle.load(file)\n",
    "    file.close()\n",
    "    print(\"features of length \" , len(features) , \" is loaded.....\")\n",
    "    # print(features[:100])\n",
    "    return features\n",
    "\n",
    "def find_features(w_features, t_words):\n",
    "    words = t_words\n",
    "    features = {}\n",
    "    for f in w_features:\n",
    "        features[f] = 0\n",
    "\n",
    "    for f in features:\n",
    "        if f in words:\n",
    "            features[f] += 1\n",
    "    return features\n",
    "\n",
    "\n",
    "def make_featuresets(word_features):\n",
    "\n",
    "    documents_f = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/T&T/testing.pickle\", \"rb\")\n",
    "    testing_files = pickle.load(documents_f)\n",
    "    documents_f.close()\n",
    "    print(str(len(testing_files)) + \" testing files loaded.....\")\n",
    "\n",
    "    testing_featureset = []\n",
    "\n",
    "    for index in range(len(testing_files)):\n",
    "        testing_featureset.append(\n",
    "            [find_features(word_features, testing_files[index][2]),\n",
    "             testing_files[index][1]])\n",
    "\n",
    "    save_featuresets = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/feature_modeling/testing_featureset.pickle\", \"wb\")\n",
    "    pickle.dump(testing_featureset, save_featuresets)\n",
    "    save_featuresets.close()\n",
    "    print(\"testing featuresets saved.....\")\n",
    "    print(\"===============>\")\n",
    "\n",
    "    for t_index in range(10):\n",
    "        documents_f = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/T&T/training\" + str(t_index + 1) +\".pickle\", \"rb\")\n",
    "        training_files = pickle.load(documents_f)\n",
    "        documents_f.close()\n",
    "        print(str(len(training_files)) + \" training files loaded.....\")\n",
    "\n",
    "        training_featureset = []\n",
    "\n",
    "        for index in range(len(training_files)):\n",
    "            training_featureset.append(\n",
    "                [find_features(word_features, training_files[index][2]),\n",
    "                 training_files[index][1]])\n",
    "\n",
    "        save_featuresets = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/feature_modeling/training_featureset\" + str(t_index + 1) + \".pickle\",\"wb\")\n",
    "        pickle.dump(training_featureset, save_featuresets)\n",
    "        save_featuresets.close()\n",
    "        print(\"training featuresets \" + str(t_index + 1) + \" saved.....\")\n",
    "        print(\"===============>\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # dataset = load_dataset()\n",
    "    features = load_features()\n",
    "    # saperate_training_and_testing_data(dataset)\n",
    "    make_featuresets(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "#### Refactoring Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of testing dataset:  1336\n",
      "iteration 1\n",
      "lenght of training dataset:  1200\n",
      "SVM for iteration 1 done.....\n",
      "=========>>\n",
      "NB for iteration 1 done.....\n",
      "=========>>\n",
      "MNB for iteration 1 done.....\n",
      "=========>>\n",
      "BNB for iteration 1 done.....\n",
      "=========>>\n",
      "LR for iteration 1 done.....\n",
      "=========>>\n",
      "RF for iteration 1 done.....\n",
      "=========>>\n",
      "iteration 2\n",
      "lenght of training dataset:  1200\n",
      "SVM for iteration 2 done.....\n",
      "=========>>\n",
      "NB for iteration 2 done.....\n",
      "=========>>\n",
      "MNB for iteration 2 done.....\n",
      "=========>>\n",
      "BNB for iteration 2 done.....\n",
      "=========>>\n",
      "LR for iteration 2 done.....\n",
      "=========>>\n",
      "RF for iteration 2 done.....\n",
      "=========>>\n",
      "iteration 3\n",
      "lenght of training dataset:  1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kritya/.pyenv/versions/3.7.5/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM for iteration 3 done.....\n",
      "=========>>\n",
      "NB for iteration 3 done.....\n",
      "=========>>\n",
      "MNB for iteration 3 done.....\n",
      "=========>>\n",
      "BNB for iteration 3 done.....\n",
      "=========>>\n",
      "LR for iteration 3 done.....\n",
      "=========>>\n",
      "RF for iteration 3 done.....\n",
      "=========>>\n",
      "iteration 4\n",
      "lenght of training dataset:  1200\n",
      "SVM for iteration 4 done.....\n",
      "=========>>\n",
      "NB for iteration 4 done.....\n",
      "=========>>\n",
      "MNB for iteration 4 done.....\n",
      "=========>>\n",
      "BNB for iteration 4 done.....\n",
      "=========>>\n",
      "LR for iteration 4 done.....\n",
      "=========>>\n",
      "RF for iteration 4 done.....\n",
      "=========>>\n",
      "iteration 5\n",
      "lenght of training dataset:  1200\n",
      "SVM for iteration 5 done.....\n",
      "=========>>\n",
      "NB for iteration 5 done.....\n",
      "=========>>\n",
      "MNB for iteration 5 done.....\n",
      "=========>>\n",
      "BNB for iteration 5 done.....\n",
      "=========>>\n",
      "LR for iteration 5 done.....\n",
      "=========>>\n",
      "RF for iteration 5 done.....\n",
      "=========>>\n",
      "iteration 6\n",
      "lenght of training dataset:  1200\n",
      "SVM for iteration 6 done.....\n",
      "=========>>\n",
      "NB for iteration 6 done.....\n",
      "=========>>\n",
      "MNB for iteration 6 done.....\n",
      "=========>>\n",
      "BNB for iteration 6 done.....\n",
      "=========>>\n",
      "LR for iteration 6 done.....\n",
      "=========>>\n",
      "RF for iteration 6 done.....\n",
      "=========>>\n",
      "iteration 7\n",
      "lenght of training dataset:  1200\n",
      "SVM for iteration 7 done.....\n",
      "=========>>\n",
      "NB for iteration 7 done.....\n",
      "=========>>\n",
      "MNB for iteration 7 done.....\n",
      "=========>>\n",
      "BNB for iteration 7 done.....\n",
      "=========>>\n",
      "LR for iteration 7 done.....\n",
      "=========>>\n",
      "RF for iteration 7 done.....\n",
      "=========>>\n",
      "iteration 8\n",
      "lenght of training dataset:  1200\n",
      "SVM for iteration 8 done.....\n",
      "=========>>\n",
      "NB for iteration 8 done.....\n",
      "=========>>\n",
      "MNB for iteration 8 done.....\n",
      "=========>>\n",
      "BNB for iteration 8 done.....\n",
      "=========>>\n",
      "LR for iteration 8 done.....\n",
      "=========>>\n",
      "RF for iteration 8 done.....\n",
      "=========>>\n",
      "iteration 9\n",
      "lenght of training dataset:  1200\n",
      "SVM for iteration 9 done.....\n",
      "=========>>\n",
      "NB for iteration 9 done.....\n",
      "=========>>\n",
      "MNB for iteration 9 done.....\n",
      "=========>>\n",
      "BNB for iteration 9 done.....\n",
      "=========>>\n",
      "LR for iteration 9 done.....\n",
      "=========>>\n",
      "RF for iteration 9 done.....\n",
      "=========>>\n",
      "iteration 10\n",
      "lenght of training dataset:  1228\n",
      "SVM for iteration 10 done.....\n",
      "=========>>\n",
      "NB for iteration 10 done.....\n",
      "=========>>\n",
      "MNB for iteration 10 done.....\n",
      "=========>>\n",
      "BNB for iteration 10 done.....\n",
      "=========>>\n",
      "LR for iteration 10 done.....\n",
      "=========>>\n",
      "RF for iteration 10 done.....\n",
      "=========>>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "classifiers = ['SVM', 'NB', 'MNB', 'BNB', 'LR', 'RF']\n",
    "# classifiers = ['SVM']\n",
    "# data loading\n",
    "featuresets_f = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/feature_modeling/testing_featureset.pickle\", \"rb\")\n",
    "testing_set = pickle.load(featuresets_f)\n",
    "featuresets_f.close()\n",
    "print(\"lenght of testing dataset: \", len(testing_set))\n",
    "\n",
    "for t_index in range(10):\n",
    "\n",
    "    print(\"iteration \" + str(t_index + 1))\n",
    "    featuresets_f = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/feature_modeling/training_featureset\" + str(t_index + 1) + \".pickle\", \"rb\")\n",
    "    training = pickle.load(featuresets_f)\n",
    "    featuresets_f.close()\n",
    "    print(\"lenght of training dataset: \", len(training))\n",
    "\n",
    "    for cls in classifiers:\n",
    "        if cls == 'SVM':\n",
    "            classifier = SklearnClassifier(LinearSVC())\n",
    "            classifier.train(training)\n",
    "        elif cls == 'NB':\n",
    "            classifier = nltk.NaiveBayesClassifier.train(training)\n",
    "            classifier.train(training)\n",
    "        elif cls == 'MNB':\n",
    "            classifier = SklearnClassifier(MultinomialNB())\n",
    "            classifier.train(training)\n",
    "        elif cls == 'BNB':\n",
    "            classifier = SklearnClassifier(BernoulliNB())\n",
    "            classifier.train(training)\n",
    "        elif cls == 'LR':\n",
    "            classifier = SklearnClassifier(LogisticRegression())\n",
    "            classifier.train(training)\n",
    "        elif cls == 'RF':\n",
    "            classifier = SklearnClassifier(RandomForestClassifier())\n",
    "            classifier.train(training)\n",
    "        # prediction\n",
    "        y_true, y_pred = [], []\n",
    "\n",
    "        for i, (feats, label_true) in enumerate(testing_set):\n",
    "            label_pred = classifier.classify(feats)\n",
    "            y_true.append(label_true)\n",
    "            y_pred.append(label_pred)\n",
    "\n",
    "        # save_classifier = open(\"./trained_classifiers/LRall.pickle\", \"wb\")\n",
    "        save_classifier = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/trained_classifiers\" + cls + str(t_index + 1) + \".pickle\", \"wb\")\n",
    "        pickle.dump(classifier, save_classifier)\n",
    "        save_classifier.close()\n",
    "\n",
    "        # save_classifier = open(\"./y_true_pred/y_true_LRall.pickle\", \"wb\")\n",
    "        save_classifier = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/y_true_pred/y_true\" + cls + str(t_index + 1) +  \".pickle\", \"wb\")\n",
    "        pickle.dump(y_true, save_classifier)\n",
    "        save_classifier.close()\n",
    "\n",
    "        # save_classifier = open(\"./y_true_pred/y_pred_LRall.pickle\", \"wb\")\n",
    "        save_classifier = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/y_true_pred/y_pred\" + cls + str(t_index + 1) +  \".pickle\", \"wb\")\n",
    "        pickle.dump(y_pred, save_classifier)\n",
    "        save_classifier.close()\n",
    "\n",
    "        print(cls + \" for iteration \" + str(t_index + 1) + \" done.....\")\n",
    "        print(\"=========>>\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "#### Multi-label Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of  SGDClassifier(alpha=0.001, max_iter=6, random_state=42, tol=None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       535\n",
      "           1       0.00      0.00      0.00       525\n",
      "           2       0.00      0.00      0.00       531\n",
      "           3       0.00      0.00      0.00       539\n",
      "           4       0.96      0.04      0.08       511\n",
      "           5       0.00      0.00      0.00       519\n",
      "           6       0.00      0.00      0.00       544\n",
      "           7       0.00      0.00      0.00       499\n",
      "           8       0.00      0.00      0.00       494\n",
      "           9       0.78      0.03      0.05       512\n",
      "          10       1.00      0.01      0.02       519\n",
      "          11       0.00      0.00      0.00       507\n",
      "          12       0.00      0.00      0.00       547\n",
      "          13       0.00      0.00      0.00       518\n",
      "\n",
      "   micro avg       0.89      0.01      0.01      7300\n",
      "   macro avg       0.20      0.01      0.01      7300\n",
      "weighted avg       0.19      0.01      0.01      7300\n",
      " samples avg       0.01      0.01      0.01      7300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kritya/.pyenv/versions/3.7.5/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kritya/.pyenv/versions/3.7.5/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of  LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91       535\n",
      "           1       0.00      0.00      0.00       525\n",
      "           2       0.95      0.83      0.89       531\n",
      "           3       0.94      0.06      0.12       539\n",
      "           4       0.94      0.59      0.73       511\n",
      "           5       0.90      0.05      0.10       519\n",
      "           6       1.00      0.09      0.17       544\n",
      "           7       1.00      0.01      0.02       499\n",
      "           8       0.94      0.81      0.87       494\n",
      "           9       0.95      0.48      0.64       512\n",
      "          10       0.97      0.78      0.87       519\n",
      "          11       0.95      0.81      0.88       507\n",
      "          12       1.00      0.08      0.15       547\n",
      "          13       1.00      0.00      0.01       518\n",
      "\n",
      "   micro avg       0.95      0.39      0.55      7300\n",
      "   macro avg       0.89      0.39      0.45      7300\n",
      "weighted avg       0.89      0.39      0.45      7300\n",
      " samples avg       0.39      0.39      0.39      7300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kritya/.pyenv/versions/3.7.5/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kritya/.pyenv/versions/3.7.5/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of  MultinomialNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.31      0.46       535\n",
      "           1       0.27      0.01      0.01       525\n",
      "           2       0.93      0.34      0.50       531\n",
      "           3       0.64      0.03      0.06       539\n",
      "           4       0.85      0.17      0.29       511\n",
      "           5       0.73      0.05      0.10       519\n",
      "           6       0.76      0.07      0.12       544\n",
      "           7       0.64      0.04      0.07       499\n",
      "           8       0.91      0.21      0.35       494\n",
      "           9       0.83      0.09      0.16       512\n",
      "          10       0.95      0.38      0.54       519\n",
      "          11       0.94      0.25      0.39       507\n",
      "          12       0.69      0.05      0.10       547\n",
      "          13       0.36      0.01      0.02       518\n",
      "\n",
      "   micro avg       0.87      0.14      0.25      7300\n",
      "   macro avg       0.74      0.14      0.23      7300\n",
      "weighted avg       0.74      0.14      0.23      7300\n",
      " samples avg       0.14      0.14      0.14      7300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kritya/.pyenv/versions/3.7.5/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of  LinearSVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       535\n",
      "           1       0.57      0.07      0.13       525\n",
      "           2       0.90      0.92      0.91       531\n",
      "           3       0.90      0.66      0.76       539\n",
      "           4       0.89      0.87      0.88       511\n",
      "           5       0.83      0.65      0.73       519\n",
      "           6       0.90      0.71      0.79       544\n",
      "           7       0.84      0.45      0.58       499\n",
      "           8       0.90      0.92      0.91       494\n",
      "           9       0.92      0.77      0.84       512\n",
      "          10       0.93      0.82      0.87       519\n",
      "          11       0.94      0.82      0.88       507\n",
      "          12       0.90      0.65      0.75       547\n",
      "          13       0.71      0.21      0.33       518\n",
      "\n",
      "   micro avg       0.89      0.68      0.77      7300\n",
      "   macro avg       0.86      0.68      0.73      7300\n",
      "weighted avg       0.86      0.68      0.73      7300\n",
      " samples avg       0.68      0.68      0.68      7300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kritya/.pyenv/versions/3.7.5/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyodbc\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "\n",
    "df_text = pd.read_csv('/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/dataset/TextPreprocessed.csv', encoding='iso-8859-1')\n",
    "# print(df_text.head())\n",
    "df_tags = pd.read_csv('/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/dataset/Tag.csv', encoding='iso-8859-1')\n",
    "\n",
    "num_classes = 14\n",
    "grouped_tags = df_tags.groupby(\"Tag\").size().reset_index(name='count')\n",
    "most_common_tags = grouped_tags.nlargest(num_classes, columns=\"count\")\n",
    "df_tags.Tag = df_tags.Tag.apply(lambda tag : tag if tag in most_common_tags.Tag.values else None)\n",
    "df_tags = df_tags.dropna()\n",
    "\n",
    "counts = df_tags.Tag.value_counts()\n",
    "firstlast = counts[:5].append(counts[-5:])\n",
    "firstlast.reset_index(name=\"count\")\n",
    "\n",
    "# print(firstlast)\n",
    "\n",
    "def tags_for_question(question_id):\n",
    "    return df_tags[df_tags['Id'] == question_id].Tag.values\n",
    "\n",
    "def add_tags_column(row):\n",
    "    row['Tags'] = tags_for_question(row['Id'])\n",
    "    return row\n",
    "\n",
    "df_questions = df_text.apply(add_tags_column, axis=1)\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df_questions.Tags)\n",
    "Y = multilabel_binarizer.transform(df_questions.Tags)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(df_questions.Text.values.astype('U'))\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "\n",
    "ros = RandomOverSampler(random_state=9000)\n",
    "X_tfidf_resampled, Y_tfidf_resampled = ros.fit_resample(X_tfidf, Y)\n",
    "\n",
    "x_train_tfidf, x_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf_resampled, Y_tfidf_resampled, test_size=0.2, random_state=9000)\n",
    "\n",
    "\n",
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    print(y_true.shape[0])\n",
    "    print(y_pred)\n",
    "\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set(np.where(y_true[i])[0])\n",
    "        set_pred = set(np.where(y_pred[i])[0])\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            # tmp_a = len(set_true.union(set_pred))\n",
    "            tmp_a = len(set_true.intersection(set_pred))/float(len(set_true.union(set_pred)) )\n",
    "        acc_list.append(tmp_a)\n",
    "    # print(acc_list)\n",
    "    return np.mean(acc_list)\n",
    "\n",
    "def print_score(y_pred, clf):\n",
    "    print(\"Clf: \", clf.__class__.__name__)\n",
    "    # print(\"Hamming loss: {}\".format(hamming_loss(y_test_tfidf, y_pred)))\n",
    "    print(\"Hamming score: {}\".format(hamming_score(y_test_tfidf, y_pred)))\n",
    "    # print('Subset accuracy: {0}'.format(accuracy_score(y_test_tfidf, y_pred, normalize=True, sample_weight=None)))\n",
    "    # print('Subset precision: {0}'.format(precision_score(y_test_tfidf, y_pred, average='samples')))\n",
    "    print(\"---\")\n",
    "\n",
    "sgd = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=6, tol=None)\n",
    "lr = LogisticRegression()\n",
    "mn = MultinomialNB()\n",
    "svm = LinearSVC()\n",
    "classifer_models = [sgd, lr, mn, svm]\n",
    "for classifier in classifer_models:\n",
    "    clf = OneVsRestClassifier(classifier)\n",
    "    clf.fit(x_train_tfidf, y_train_tfidf)\n",
    "    y_pred = clf.predict(x_test_tfidf)\n",
    "    # print_score(y_pred, classifier)\n",
    "    print(\"Classification Report of \", classifier)\n",
    "    print(classification_report(y_test_tfidf, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('3.7.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "045a75943006dc8e45f4d691aabc45fab2fabf7f0669ad03a22a8689120c3622"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
