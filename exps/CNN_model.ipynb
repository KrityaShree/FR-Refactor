{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model for Binary Classification (Need for refactoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pre-processed</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modif roo command enhanc usabl consist add on...</td>\n",
       "      <td>1</td>\n",
       "      <td>[modif, roo, command, enhanc, usabl, consist, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>add debug trace zk procedur add debug trace l...</td>\n",
       "      <td>0</td>\n",
       "      <td>[debug, trace, zk, procedur, debug, trace, log...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>expos listpeerconfig getpeerconfig hbase shel...</td>\n",
       "      <td>0</td>\n",
       "      <td>[expo, getpeerconfig, shell, getpeerconfig, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>choos data access pattern time aspect gener a...</td>\n",
       "      <td>1</td>\n",
       "      <td>[data, access, pattern, time, aspect, gener, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distribut search mode use grpc user give sql ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[distribut, search, mode, grpc, sql, statement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13359</th>\n",
       "      <td>provid separ read write thread bookkeep serve...</td>\n",
       "      <td>1</td>\n",
       "      <td>[provid, separ, write, thread, bookkeep, serve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13360</th>\n",
       "      <td>signific perform improv per current metadata ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[signific, perform, improv, current, metadata,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13361</th>\n",
       "      <td>finer grain log metric split transact split t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[finer, grain, log, metric, split, transact, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13362</th>\n",
       "      <td>updat atla architectur wiki new addit atla ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>[updat, atla, architectur, addit, atla, archit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13363</th>\n",
       "      <td>maven sling plugin allow instal bundl slingpo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[sling, plugin, instal, bundl, slingpostservle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Pre-processed  label  \\\n",
       "0       modif roo command enhanc usabl consist add on...      1   \n",
       "1       add debug trace zk procedur add debug trace l...      0   \n",
       "2       expos listpeerconfig getpeerconfig hbase shel...      0   \n",
       "3       choos data access pattern time aspect gener a...      1   \n",
       "4       distribut search mode use grpc user give sql ...      1   \n",
       "...                                                  ...    ...   \n",
       "13359   provid separ read write thread bookkeep serve...      1   \n",
       "13360   signific perform improv per current metadata ...      1   \n",
       "13361   finer grain log metric split transact split t...      0   \n",
       "13362   updat atla architectur wiki new addit atla ar...      0   \n",
       "13363   maven sling plugin allow instal bundl slingpo...      1   \n",
       "\n",
       "                                                  lemmas  \n",
       "0      [modif, roo, command, enhanc, usabl, consist, ...  \n",
       "1      [debug, trace, zk, procedur, debug, trace, log...  \n",
       "2      [expo, getpeerconfig, shell, getpeerconfig, re...  \n",
       "3      [data, access, pattern, time, aspect, gener, a...  \n",
       "4      [distribut, search, mode, grpc, sql, statement...  \n",
       "...                                                  ...  \n",
       "13359  [provid, separ, write, thread, bookkeep, serve...  \n",
       "13360  [signific, perform, improv, current, metadata,...  \n",
       "13361  [finer, grain, log, metric, split, transact, s...  \n",
       "13362  [updat, atla, architectur, addit, atla, archit...  \n",
       "13363  [sling, plugin, instal, bundl, slingpostservle...  \n",
       "\n",
       "[13364 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Importing preprocessed dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#Loading the dataset\n",
    "df = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/dataset/shuffle_dataset.pickle\", \"rb\")\n",
    "dataset = pickle.load(df)\n",
    "df.close()\n",
    "\n",
    "# Loading the frequent words set\n",
    "df1 = open(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/dataset/freq_words_after_preprocessing.pickle\", \"rb\")\n",
    "freq_words = pickle.load(df1)\n",
    "df1.close()\n",
    "\n",
    "data = pd.DataFrame(dataset, columns=[\"Pre-processed\", \"label\", \"lemmas\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['code',\n",
       " 'support',\n",
       " 'apach',\n",
       " 'current',\n",
       " 'class',\n",
       " 'java',\n",
       " 'sling',\n",
       " 'implement',\n",
       " 'file',\n",
       " 'http',\n",
       " 'method',\n",
       " 'creat',\n",
       " 'test',\n",
       " 'type',\n",
       " 'configur',\n",
       " 'provid',\n",
       " 'data',\n",
       " 'chang',\n",
       " 'user',\n",
       " 'time',\n",
       " 'client',\n",
       " 'valu',\n",
       " 'gener',\n",
       " 'hbase',\n",
       " 'string',\n",
       " 'case',\n",
       " 'list',\n",
       " 'default',\n",
       " 'properti',\n",
       " 'resourc',\n",
       " 'org',\n",
       " 'version',\n",
       " 'tabl',\n",
       " 'project',\n",
       " 'api',\n",
       " 'servic',\n",
       " 'base',\n",
       " 'option',\n",
       " 'log',\n",
       " 'request',\n",
       " 'messag',\n",
       " 'queri',\n",
       " 'updat',\n",
       " 'remov',\n",
       " 'interfac',\n",
       " 'ad',\n",
       " 'improv',\n",
       " 'work',\n",
       " 'error',\n",
       " 'function',\n",
       " 'exampl',\n",
       " 'issu',\n",
       " 'call',\n",
       " 'bundl',\n",
       " 'applic',\n",
       " 'content',\n",
       " 'process',\n",
       " 'modul',\n",
       " 'map',\n",
       " 'requir',\n",
       " 'access',\n",
       " 'load',\n",
       " 'result',\n",
       " 'util',\n",
       " 'job',\n",
       " 'number',\n",
       " 'handl',\n",
       " 'path',\n",
       " 'script',\n",
       " 'document',\n",
       " 'patch',\n",
       " 'compon',\n",
       " 'includ',\n",
       " 'possibl',\n",
       " 'thread',\n",
       " 'region',\n",
       " 'system',\n",
       " 'public',\n",
       " 'order',\n",
       " 'featur',\n",
       " 'field',\n",
       " 'cluster',\n",
       " 'server',\n",
       " 'instanc',\n",
       " 'key',\n",
       " 'core',\n",
       " 'store',\n",
       " 'return',\n",
       " 'node',\n",
       " 'html',\n",
       " 'jcr',\n",
       " 'command',\n",
       " 'main',\n",
       " 'hadoop',\n",
       " 'common',\n",
       " 'xml',\n",
       " 'jar',\n",
       " 'column',\n",
       " 'packag',\n",
       " 'model',\n",
       " 'defin',\n",
       " 'specif',\n",
       " 'stream',\n",
       " 'addit',\n",
       " 'pdfbox',\n",
       " 'inform',\n",
       " 'level',\n",
       " 'event',\n",
       " 'state',\n",
       " 'repositori',\n",
       " 'web',\n",
       " 'context',\n",
       " 'size',\n",
       " 'multipl',\n",
       " 'spring',\n",
       " 'filter',\n",
       " 'custom',\n",
       " 'instal',\n",
       " 'import',\n",
       " 'perform',\n",
       " 'problem',\n",
       " 'integr',\n",
       " 'refactor',\n",
       " 'memori',\n",
       " 'allow',\n",
       " 'manag',\n",
       " 'info',\n",
       " 'sinc',\n",
       " 'start',\n",
       " 'check',\n",
       " 'json',\n",
       " 'config',\n",
       " 'local',\n",
       " 'move',\n",
       " 'mani',\n",
       " 'object',\n",
       " 'null',\n",
       " 'task',\n",
       " 'valid',\n",
       " 'abl',\n",
       " 'output',\n",
       " 'singl',\n",
       " 'follow',\n",
       " 'avail',\n",
       " 'howev',\n",
       " 'write',\n",
       " 'scan',\n",
       " 'url',\n",
       " 'specifi',\n",
       " 'authent',\n",
       " 'pas',\n",
       " 'propos',\n",
       " 'roo',\n",
       " 'block',\n",
       " 'pdf',\n",
       " 'relat',\n",
       " 'master',\n",
       " 'sourc',\n",
       " 'github',\n",
       " 'differ',\n",
       " 'thing',\n",
       " 'actual',\n",
       " 'plugin',\n",
       " 'control',\n",
       " 'par',\n",
       " 'row',\n",
       " 'tri',\n",
       " 'framework',\n",
       " 'servlet',\n",
       " 'releas',\n",
       " 'side',\n",
       " 'annot',\n",
       " 'replac',\n",
       " 'intern',\n",
       " 'simpl',\n",
       " 'final',\n",
       " 'tool',\n",
       " 'initi',\n",
       " 'session',\n",
       " 'input',\n",
       " 'group',\n",
       " 'cach',\n",
       " 'caus',\n",
       " 'groovi',\n",
       " 'text',\n",
       " 'jira',\n",
       " 'templat',\n",
       " 'databas',\n",
       " 'alreadi',\n",
       " 'limit',\n",
       " 'good',\n",
       " 'true',\n",
       " 'discus',\n",
       " 'separ',\n",
       " 'attribut',\n",
       " 'int',\n",
       " 'mail',\n",
       " 'express',\n",
       " 'complet',\n",
       " 'metadata',\n",
       " 'form',\n",
       " 'clean',\n",
       " 'format',\n",
       " 'static',\n",
       " 'partit',\n",
       " 'place',\n",
       " 'respons',\n",
       " 'enabl',\n",
       " 'lot',\n",
       " 'metric',\n",
       " 'storm',\n",
       " 'reason',\n",
       " 'runtim',\n",
       " 'copi',\n",
       " 'introduc',\n",
       " 'schema',\n",
       " 'src',\n",
       " 'view',\n",
       " 'osgi',\n",
       " 'byte',\n",
       " 'select',\n",
       " 'element',\n",
       " 'logic',\n",
       " 'serial',\n",
       " 'header',\n",
       " 'join',\n",
       " 'iter',\n",
       " 'record',\n",
       " 'sort',\n",
       " 'io',\n",
       " 'cayenn',\n",
       " 'idea',\n",
       " 'locat',\n",
       " 'delet',\n",
       " 'channel',\n",
       " 'sampl',\n",
       " 'doc',\n",
       " 'unit',\n",
       " 'tajo',\n",
       " 'handler',\n",
       " 'tag',\n",
       " 'consum',\n",
       " 'expo',\n",
       " 'sql',\n",
       " 'post',\n",
       " 'second',\n",
       " 'compil',\n",
       " 'tapestri',\n",
       " 'adapt',\n",
       " 'plan',\n",
       " 'add',\n",
       " 'point',\n",
       " 'resolv',\n",
       " 'search',\n",
       " 'detail',\n",
       " 'display',\n",
       " 'directori',\n",
       " 'basic',\n",
       " 'paramet',\n",
       " 'noformat',\n",
       " 'worker',\n",
       " 'larg',\n",
       " 'shell',\n",
       " 'avoid',\n",
       " 'reduc',\n",
       " 'snapshot',\n",
       " 'fals',\n",
       " 'connect',\n",
       " 'parent',\n",
       " 'hive',\n",
       " 'compact',\n",
       " 'replic',\n",
       " 'usag',\n",
       " 'mode',\n",
       " 'jdbc',\n",
       " 'directli',\n",
       " 'merg',\n",
       " 'port',\n",
       " 'rest',\n",
       " 'deprec',\n",
       " 'convert',\n",
       " 'librari',\n",
       " 'regist',\n",
       " 'help',\n",
       " 'share',\n",
       " 'void',\n",
       " 'array',\n",
       " 'someth',\n",
       " 'modifi',\n",
       " 'action',\n",
       " 'count',\n",
       " 'rule',\n",
       " 'jsp',\n",
       " 'small',\n",
       " 'mock',\n",
       " 'mechan',\n",
       " 'easy',\n",
       " 'deploy',\n",
       " 'enhanc',\n",
       " 'debug',\n",
       " 'kafka',\n",
       " 'fail',\n",
       " 'report',\n",
       " 'behavior',\n",
       " 'open',\n",
       " 'distribut',\n",
       " 'hdf',\n",
       " 'overrid',\n",
       " 'color',\n",
       " 'upgrad',\n",
       " 'creation',\n",
       " 'secur',\n",
       " 'pattern',\n",
       " 'regionserv',\n",
       " 'disabl',\n",
       " 'argument',\n",
       " 'target',\n",
       " 'tree',\n",
       " 'variabl',\n",
       " 'setup',\n",
       " 'ui',\n",
       " 'optim',\n",
       " 'statement',\n",
       " 'comment',\n",
       " 'impl',\n",
       " 'root',\n",
       " 'consol',\n",
       " 'dev',\n",
       " 'imag',\n",
       " 'lang',\n",
       " 'compat',\n",
       " 'render',\n",
       " 'auto',\n",
       " 'throw',\n",
       " 'zookeep',\n",
       " 'space',\n",
       " 'activ',\n",
       " 'approach',\n",
       " 'match',\n",
       " 'note',\n",
       " 'split',\n",
       " 'solut',\n",
       " 'high',\n",
       " 'assign',\n",
       " 'consid',\n",
       " 'full',\n",
       " 'queue',\n",
       " 'long',\n",
       " 'concurr',\n",
       " 'build',\n",
       " 'insid',\n",
       " 'invok',\n",
       " 'extern',\n",
       " 'address',\n",
       " 'execut',\n",
       " 'transform',\n",
       " 'produc',\n",
       " 'product',\n",
       " 'pool',\n",
       " 'track',\n",
       " 'constructor',\n",
       " 'flag',\n",
       " 'export',\n",
       " 'late',\n",
       " 'thu',\n",
       " 'step',\n",
       " 'bit',\n",
       " 'abil',\n",
       " 'revers',\n",
       " 'structur',\n",
       " 'low',\n",
       " 'failur',\n",
       " 'foo',\n",
       " 'renam',\n",
       " 'entiti',\n",
       " 'sure',\n",
       " 'bug',\n",
       " 'appli',\n",
       " 'receiv',\n",
       " 'window',\n",
       " 'edit',\n",
       " 'everi',\n",
       " 'persist',\n",
       " 'privat',\n",
       " 'commit',\n",
       " 'pom',\n",
       " 'boolean',\n",
       " 'flush',\n",
       " 'ling',\n",
       " 'trunk',\n",
       " 'batch',\n",
       " 'item',\n",
       " 'depend',\n",
       " 'close',\n",
       " 'artifact',\n",
       " 'proxi',\n",
       " 'googl',\n",
       " 'db',\n",
       " 'sh',\n",
       " 'automat',\n",
       " 'cwiki',\n",
       " 'abstract',\n",
       " 'aggreg',\n",
       " 'probabl',\n",
       " 'transact',\n",
       " 'compress',\n",
       " 'complex',\n",
       " 'factori',\n",
       " 'multi',\n",
       " 'markmail',\n",
       " 'schedul',\n",
       " 'print',\n",
       " 'engin',\n",
       " 'simplifi',\n",
       " 'launchpad',\n",
       " 'environ',\n",
       " 'scope',\n",
       " 'font',\n",
       " 'attach',\n",
       " 'languag',\n",
       " 'graph',\n",
       " 'standard',\n",
       " 'dynam',\n",
       " 'accumulo',\n",
       " 'style',\n",
       " 'realli',\n",
       " 'mayb',\n",
       " 'folder',\n",
       " 'easi',\n",
       " 'entri',\n",
       " 'spark',\n",
       " 'javadoc',\n",
       " 'plea',\n",
       " 'global',\n",
       " 'max',\n",
       " 'normal',\n",
       " 'webapp',\n",
       " 'topolog',\n",
       " 'hard',\n",
       " 'length',\n",
       " 'rpc',\n",
       " 'jackrabbit',\n",
       " 'runner',\n",
       " 'param',\n",
       " 'duplic',\n",
       " 'jpa',\n",
       " 'startup',\n",
       " 'jobmanag',\n",
       " 'meta',\n",
       " 'inherit',\n",
       " 'origin',\n",
       " 'goal',\n",
       " 'scenario',\n",
       " 'fact',\n",
       " 'topic',\n",
       " 'impala',\n",
       " 'uri',\n",
       " 'special',\n",
       " 'host',\n",
       " 'describ',\n",
       " 'lock',\n",
       " 'variou',\n",
       " 'top',\n",
       " 'especi',\n",
       " 'strategi',\n",
       " 'manual',\n",
       " 'subsystem',\n",
       " 'direct',\n",
       " 'loader',\n",
       " 'tupl',\n",
       " 'inject',\n",
       " 'parser',\n",
       " 'program',\n",
       " 'statu',\n",
       " 'design',\n",
       " 'ignor',\n",
       " 'definit',\n",
       " 'therefor',\n",
       " 'disk',\n",
       " 'wicket',\n",
       " 'label',\n",
       " 'read',\n",
       " 'el',\n",
       " 'bean',\n",
       " 'brow',\n",
       " 'discoveri',\n",
       " 'subclass',\n",
       " 'fragment',\n",
       " 'submit',\n",
       " 'necessari',\n",
       " 'charact',\n",
       " 'compar',\n",
       " 'contribut',\n",
       " 'timestamp',\n",
       " 'encod',\n",
       " 'download',\n",
       " 'felix',\n",
       " 'javascript',\n",
       " 'parquet',\n",
       " 'builder',\n",
       " 'drop',\n",
       " 'lib',\n",
       " 'archiv',\n",
       " 'consist',\n",
       " 'storag',\n",
       " 'sever',\n",
       " 'extract',\n",
       " 'jena',\n",
       " 'awar',\n",
       " 'great',\n",
       " 'app',\n",
       " 'profil',\n",
       " 'easili',\n",
       " 'determin',\n",
       " 'sen',\n",
       " 'distinct',\n",
       " 'trigger',\n",
       " 'prevent',\n",
       " 'amount',\n",
       " 'indic',\n",
       " 'identifi',\n",
       " 'scanner',\n",
       " 'javassist',\n",
       " 'remot',\n",
       " 'driver',\n",
       " 'big',\n",
       " 'declar',\n",
       " 'catalog',\n",
       " 'hash',\n",
       " 'descript',\n",
       " 'convers',\n",
       " 'svn',\n",
       " 'condit',\n",
       " 'futur',\n",
       " 'net',\n",
       " 'slow',\n",
       " 'refer',\n",
       " 'admin',\n",
       " 'cell',\n",
       " 'pull',\n",
       " 'quot',\n",
       " 'filesystem',\n",
       " 'total',\n",
       " 'wrap',\n",
       " 'closur',\n",
       " 'zk',\n",
       " 'javax',\n",
       " 'junit',\n",
       " 'insert',\n",
       " 'discuss',\n",
       " 'unnecessari',\n",
       " 'cleanup',\n",
       " 'child',\n",
       " 'wait',\n",
       " 'microsl',\n",
       " 'transport',\n",
       " 'blob',\n",
       " 'binari',\n",
       " 'collect',\n",
       " 'namespac',\n",
       " 'purpos',\n",
       " 'push',\n",
       " 'site',\n",
       " 'combin',\n",
       " 'sdk',\n",
       " 'detect',\n",
       " 'reader',\n",
       " 'retriev',\n",
       " 'clear',\n",
       " 'peopl',\n",
       " 'ideal',\n",
       " 'capabl',\n",
       " 'sometim',\n",
       " 'rang',\n",
       " 'classpath',\n",
       " 'extra',\n",
       " 'exist',\n",
       " 'success',\n",
       " 'layer',\n",
       " 'comput',\n",
       " 'springframework',\n",
       " 'endpoint',\n",
       " 'syntax',\n",
       " 'empti',\n",
       " 'giraph',\n",
       " 'wal',\n",
       " 'synchron',\n",
       " 'prefix',\n",
       " 'increas',\n",
       " 'major',\n",
       " 'notic',\n",
       " 'password',\n",
       " 'localhost',\n",
       " 'resourceresolv',\n",
       " 'hfile',\n",
       " 'stack',\n",
       " 'situat',\n",
       " 'integ',\n",
       " 'trace',\n",
       " 'confus',\n",
       " 'init',\n",
       " 'coupl',\n",
       " 'equal',\n",
       " 'kind',\n",
       " 'jvm',\n",
       " 'warn',\n",
       " 'bar',\n",
       " 'network',\n",
       " 'lead',\n",
       " 'scala',\n",
       " 'jmx',\n",
       " 'simpli',\n",
       " 'mark',\n",
       " 'connector',\n",
       " 'switch',\n",
       " 'everyth',\n",
       " 'correct',\n",
       " 'migrat',\n",
       " 'ensur',\n",
       " 'quit',\n",
       " 'upload',\n",
       " 'sun',\n",
       " 'break',\n",
       " 'real',\n",
       " 'extens',\n",
       " 'beam',\n",
       " 'src_main_java',\n",
       " 'relationship',\n",
       " 'writer',\n",
       " 'credenti',\n",
       " 'deal',\n",
       " 'correctli',\n",
       " 'hlog',\n",
       " 'becom',\n",
       " 'login',\n",
       " 'forc',\n",
       " 'belgium',\n",
       " 'incub',\n",
       " 'constant',\n",
       " 'random',\n",
       " 'balanc',\n",
       " 'attempt',\n",
       " 'wrong',\n",
       " 'effici',\n",
       " 'term',\n",
       " 'mongo',\n",
       " 'evalu',\n",
       " 'box',\n",
       " 'jcloud',\n",
       " 'progress',\n",
       " 'polici',\n",
       " 'protocol',\n",
       " 'correspond',\n",
       " 'decid',\n",
       " 'nest',\n",
       " 'fine',\n",
       " 'flow',\n",
       " 'gc',\n",
       " 'sync',\n",
       " 'oper',\n",
       " 'chain',\n",
       " 'helper',\n",
       " 'repo',\n",
       " 'appropri',\n",
       " 'mongodb',\n",
       " 'link',\n",
       " 'minor',\n",
       " 'nice',\n",
       " 'visibl',\n",
       " 'tablet',\n",
       " 'carbondata',\n",
       " 'safe',\n",
       " 'lookup',\n",
       " 'cpu',\n",
       " 'skip',\n",
       " 'netti',\n",
       " 'alloc',\n",
       " 'monitor',\n",
       " 'axis2',\n",
       " 'classload',\n",
       " 'review',\n",
       " 'domain',\n",
       " 'altern',\n",
       " 'sequenc',\n",
       " 'inbound',\n",
       " 'rel',\n",
       " 'logger',\n",
       " 'jm',\n",
       " 'increment',\n",
       " 'underli',\n",
       " 'desir',\n",
       " 'permiss',\n",
       " 'properli',\n",
       " 'parallel',\n",
       " 'continu',\n",
       " 'resolut',\n",
       " 'usual',\n",
       " 'doubl',\n",
       " 'branch',\n",
       " 'restor',\n",
       " 'blueprint',\n",
       " 'reus',\n",
       " 'titl',\n",
       " 'accord',\n",
       " 'send',\n",
       " 'registr',\n",
       " 'construct',\n",
       " 'respect',\n",
       " 'invalid',\n",
       " 'behaviour',\n",
       " 'conf',\n",
       " 'pdpage',\n",
       " 'coprocessor',\n",
       " 'war',\n",
       " 'async',\n",
       " 'assum',\n",
       " 'restart',\n",
       " 'publish',\n",
       " 'concept',\n",
       " 'verifi',\n",
       " 'littl',\n",
       " 'author',\n",
       " 'health',\n",
       " 'sentri',\n",
       " 'bad',\n",
       " 'nativ',\n",
       " 'rewrit',\n",
       " 'vertex',\n",
       " 'understand',\n",
       " 'privileg',\n",
       " 'super',\n",
       " 'pivot',\n",
       " 'prioriti',\n",
       " 'executor',\n",
       " 'pre',\n",
       " 'potenti',\n",
       " 'extend',\n",
       " 'explicit',\n",
       " 'entir',\n",
       " 'anyth',\n",
       " 'ticket',\n",
       " 'moment',\n",
       " 'solv',\n",
       " 'veloc',\n",
       " 'maven',\n",
       " 'dispatch',\n",
       " 'individu',\n",
       " 'hregion',\n",
       " 'commun',\n",
       " 'short',\n",
       " 'finish',\n",
       " 'loop',\n",
       " 'cs',\n",
       " 'convent',\n",
       " 'eclips',\n",
       " 'stuff',\n",
       " 'year',\n",
       " 'ari',\n",
       " 'difficult',\n",
       " 'period',\n",
       " 'prototyp',\n",
       " 'famili',\n",
       " 'spec',\n",
       " 'interest',\n",
       " 'ant',\n",
       " 'immedi',\n",
       " 'machin',\n",
       " 'var',\n",
       " 'segment',\n",
       " 'mb',\n",
       " 'pick',\n",
       " 'roll',\n",
       " 'thrift',\n",
       " 'broker',\n",
       " 'stanbol',\n",
       " 'provis',\n",
       " 'today',\n",
       " 'guid',\n",
       " 'drill',\n",
       " 'icon',\n",
       " 'socket',\n",
       " 'translat',\n",
       " 'retri',\n",
       " 'oak',\n",
       " 'nabbl',\n",
       " 'tostr',\n",
       " 'anonfun',\n",
       " 'free',\n",
       " 'cover',\n",
       " 'question',\n",
       " 'proper',\n",
       " 'partial',\n",
       " 'payload',\n",
       " 'day',\n",
       " 'explicitli',\n",
       " 'benefit',\n",
       " 'set',\n",
       " 'catch',\n",
       " 'equival',\n",
       " 'signatur',\n",
       " 'mbean',\n",
       " 'flink',\n",
       " 'addon',\n",
       " 'undo',\n",
       " 'perhap',\n",
       " 'mention',\n",
       " 'maintain',\n",
       " 'scale',\n",
       " 'sign',\n",
       " 'boot',\n",
       " 'minut',\n",
       " 'fetch',\n",
       " 'carbon',\n",
       " 'stage',\n",
       " 'speed',\n",
       " 'involv',\n",
       " 'phase',\n",
       " 'ontolog',\n",
       " 'restrict',\n",
       " 'bin',\n",
       " 'editor',\n",
       " 'webdav',\n",
       " 'tmp',\n",
       " 'interact',\n",
       " 'qualifi',\n",
       " 'previou',\n",
       " 'member',\n",
       " 'conveni',\n",
       " 'processor',\n",
       " 'slotmanag',\n",
       " 'confluenc',\n",
       " 'reli',\n",
       " 'superstep',\n",
       " 'button',\n",
       " 'callback',\n",
       " 'algorithm',\n",
       " 'deleg',\n",
       " 'standalon',\n",
       " 'stat',\n",
       " 'poll',\n",
       " 'min',\n",
       " 'vector',\n",
       " 'sum',\n",
       " 'instanti',\n",
       " 'unfortun',\n",
       " 'regular',\n",
       " 'dao',\n",
       " 'union',\n",
       " 'unus',\n",
       " 'bind',\n",
       " 'quickli',\n",
       " 'flexibl',\n",
       " 'soap',\n",
       " 'fulli',\n",
       " 'account',\n",
       " 'represent',\n",
       " 'alter',\n",
       " 'leader',\n",
       " 'best',\n",
       " 'enum',\n",
       " 'maximum',\n",
       " 'tcp',\n",
       " 'backup',\n",
       " 'jsf',\n",
       " 'inf',\n",
       " 'mod_mbox',\n",
       " 'mbox',\n",
       " 'git',\n",
       " 'resourcemanag',\n",
       " 'codehau',\n",
       " 'archiva',\n",
       " 'suit',\n",
       " 'heap',\n",
       " 'checkpoint',\n",
       " 'def',\n",
       " 'person',\n",
       " 'gwt',\n",
       " 'groupid',\n",
       " 'cost',\n",
       " 'predic',\n",
       " 'otherwis',\n",
       " 'observ',\n",
       " 'inconsist',\n",
       " 'python',\n",
       " 'mutat',\n",
       " 'role',\n",
       " 'pddocument',\n",
       " 'hibern',\n",
       " 'invoc',\n",
       " 'df',\n",
       " 'artifactid',\n",
       " 'leav',\n",
       " 'variant',\n",
       " 'outsid',\n",
       " 'kerbero',\n",
       " 'cli',\n",
       " 'intermedi',\n",
       " 'bulk',\n",
       " 'mvc',\n",
       " 'jersey',\n",
       " 'selector',\n",
       " 'pdmodel',\n",
       " 'regard',\n",
       " 'signific',\n",
       " 'posit',\n",
       " 'rdf',\n",
       " 'overhead',\n",
       " 'conflict',\n",
       " 'deseri',\n",
       " 'inner',\n",
       " 'hook',\n",
       " 'planner',\n",
       " 'associ',\n",
       " 'gateway',\n",
       " 'usabl',\n",
       " 'threadpoolexecutor',\n",
       " 'grant',\n",
       " 'liter',\n",
       " 'cours',\n",
       " 'physic',\n",
       " 'browser',\n",
       " 'aspect',\n",
       " 'hand',\n",
       " 'dictionari',\n",
       " 'audit',\n",
       " 'pipelin',\n",
       " 'mysql',\n",
       " 't1',\n",
       " 'complic',\n",
       " 'bookkeep',\n",
       " 'ode',\n",
       " 'ipc',\n",
       " 'rid',\n",
       " 'serv',\n",
       " 'semant',\n",
       " 'hint',\n",
       " 'incom',\n",
       " 'diff',\n",
       " 'procedur',\n",
       " 'matrix',\n",
       " 'lucen',\n",
       " 'dsl',\n",
       " 'calcul',\n",
       " 'constraint',\n",
       " 'suppli',\n",
       " 'singleton',\n",
       " 'happen',\n",
       " 'datamap',\n",
       " 'mapreduc',\n",
       " 'care',\n",
       " 'adob',\n",
       " 'agent',\n",
       " 'memstor',\n",
       " 'offer',\n",
       " 'guava',\n",
       " 'pair',\n",
       " 'summari',\n",
       " 'vertic',\n",
       " 'watch',\n",
       " 'relev',\n",
       " 'modif',\n",
       " 'treat',\n",
       " 'enter',\n",
       " 'csv',\n",
       " 'shutdown',\n",
       " 'skin',\n",
       " 'spi',\n",
       " 'uniqu',\n",
       " 'anymor',\n",
       " 'immut',\n",
       " 'pr',\n",
       " 'blah',\n",
       " 's3',\n",
       " 'dir',\n",
       " 'primari',\n",
       " 'infrastructur',\n",
       " 'hierarchi',\n",
       " 'synaps',\n",
       " 'word',\n",
       " 'exclud',\n",
       " 'live',\n",
       " 'pipe',\n",
       " 'ajax',\n",
       " 'wcm',\n",
       " 'delay',\n",
       " 'thrown',\n",
       " 'screen',\n",
       " 'calcit',\n",
       " 'readm',\n",
       " 'latenc',\n",
       " 'wiki',\n",
       " 'scheme',\n",
       " 'sourceforg',\n",
       " 'exactli',\n",
       " 'assert',\n",
       " 'contrib',\n",
       " 'coder',\n",
       " 'pretti',\n",
       " 'setter',\n",
       " 'overal',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8922                              post code refactor clean\n",
      "2676      creat script verifi releas artifact helper sc...\n",
      "12540     replicationsourcemanag abl track multipl wal ...\n",
      "9343      defin proper contentresolv servic map request...\n",
      "13148     provid custom navig provis model featur file ...\n",
      "                               ...                        \n",
      "11964     revis code_convent current code_convent file ...\n",
      "5191      gener report show project field defin report ...\n",
      "5390      intern refactor better support meta annot met...\n",
      "860       expos bucketcach valu configur bucketcach alw...\n",
      "7270      provid healthcheckexecutor servic goal abl ge...\n",
      "Name: Pre-processed, Length: 9354, dtype: object\n",
      "8922     1\n",
      "2676     0\n",
      "12540    1\n",
      "9343     1\n",
      "13148    1\n",
      "        ..\n",
      "11964    0\n",
      "5191     1\n",
      "5390     1\n",
      "860      1\n",
      "7270     1\n",
      "Name: label, Length: 9354, dtype: int64\n",
      "Shape of training data: \n",
      "(9354,)\n",
      "(9354,)\n",
      "168       synchron tab model objent dbentiti editor pan...\n",
      "11711     use dedic thread releas resourc alloc contain...\n",
      "1621      testqueryservicedupl fail teardown test class...\n",
      "3576      java new produc io thread name must includ cl...\n",
      "7435      coprocessor design improv two main chang ad t...\n",
      "                               ...                        \n",
      "4352      move compress decompress encod specif encod c...\n",
      "7689      hbase creat hbase specif mapfil implement tod...\n",
      "788       refin connect state vlt repositori cach node ...\n",
      "6733      provid mean extern manual defin queri current...\n",
      "5610      allow certain mehtod call null cannot call nu...\n",
      "Name: Pre-processed, Length: 4010, dtype: object\n",
      "168      0\n",
      "11711    1\n",
      "1621     0\n",
      "3576     0\n",
      "7435     1\n",
      "        ..\n",
      "4352     1\n",
      "7689     1\n",
      "788      1\n",
      "6733     0\n",
      "5610     0\n",
      "Name: label, Length: 4010, dtype: int64\n",
      "Shape of test data: \n",
      "(4010,)\n",
      "(4010,)\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "train = data['Pre-processed']\n",
    "test = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, test, test_size=0.30, random_state=42)\n",
    "\n",
    "\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4484\n"
     ]
    }
   ],
   "source": [
    "# max length of review calculation\n",
    "maxi=-1\n",
    "for i,rev in enumerate(data['Pre-processed']):\n",
    "    tokens=rev.split()\n",
    "    if(len(tokens)>maxi):\n",
    "        maxi=len(tokens)\n",
    "print(maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_index = tokenizer.word_index\n",
    "vocab_len = len(words_to_index)+1\n",
    "embed_vector_len = 128\n",
    "maxLen = 4484 #Maximum review length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_words = len(X_train[1])\n",
    "# Create a tokenizer object\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "# Fit the tokenizer on the training data\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the text data to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to have a fixed length\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "pad_rev= pad_sequences(X_train_seq, maxlen=maxLen, padding='post')\n",
    "pad_rev.shape \n",
    "\n",
    "# X_train_pad = pad_sequences(X_train_seq, maxlen=maxLen, padding='post')\n",
    "# X_test_pad = pad_sequences(X_test_seq, maxlen=maxLen, padding='post')\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_words)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "74/74 [==============================] - 6s 60ms/step - loss: 0.6624 - accuracy: 0.5930 - val_loss: 0.6564 - val_accuracy: 0.6077\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 4s 58ms/step - loss: 0.6430 - accuracy: 0.6218 - val_loss: 0.6351 - val_accuracy: 0.6404\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 4s 58ms/step - loss: 0.6222 - accuracy: 0.6472 - val_loss: 0.6265 - val_accuracy: 0.6484\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 4s 57ms/step - loss: 0.6034 - accuracy: 0.6620 - val_loss: 0.6232 - val_accuracy: 0.6504\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 4s 58ms/step - loss: 0.5645 - accuracy: 0.7017 - val_loss: 0.6248 - val_accuracy: 0.6469\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 4s 59ms/step - loss: 0.5271 - accuracy: 0.7332 - val_loss: 0.6572 - val_accuracy: 0.6416\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 5s 61ms/step - loss: 0.4725 - accuracy: 0.7710 - val_loss: 0.7071 - val_accuracy: 0.6509\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 5s 62ms/step - loss: 0.4274 - accuracy: 0.8006 - val_loss: 0.7505 - val_accuracy: 0.6389\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 5s 71ms/step - loss: 0.4002 - accuracy: 0.8176 - val_loss: 0.8012 - val_accuracy: 0.6449\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 4s 59ms/step - loss: 0.3471 - accuracy: 0.8437 - val_loss: 0.8450 - val_accuracy: 0.6439\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.layers import InputLayer\n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=max_words, trainable=True)\n",
    "\n",
    "# # Building the CNN Model\n",
    "model = tensorflow.keras.Sequential()    \n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(64, 2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(32, 2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(16, 2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_pad, y_train, batch_size=128, epochs=10, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 2ms/step\n",
      "[[0.68936014]\n",
      " [0.801608  ]\n",
      " [0.6557186 ]\n",
      " ...\n",
      " [0.95120764]\n",
      " [0.9041233 ]\n",
      " [0.98501736]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_pad)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 2ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.54      0.55      1608\n",
      "           1       0.70      0.72      0.71      2402\n",
      "\n",
      "    accuracy                           0.64      4010\n",
      "   macro avg       0.63      0.63      0.63      4010\n",
      "weighted avg       0.64      0.64      0.64      4010\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 862  746]\n",
      " [ 684 1718]]\n",
      "Accuracy:  0.6433915211970075\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_pred = model.predict(X_test_pad)\n",
    "\n",
    "\n",
    "# Get the actual labels for the test data\n",
    "y_true = y_test\n",
    "\n",
    "threshold = 0.6\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "\n",
    "# Generate the classification report\n",
    "print('Classification Report:')\n",
    "report = classification_report(y_true, y_pred_binary)\n",
    "print(report)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_binary))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model for Multi-class Classsification (Type of refactoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5420</td>\n",
       "      <td>allow sqloper overridden valid calcit allow f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5421</td>\n",
       "      <td>allow sqloper overridden valid calcit allow f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5422</td>\n",
       "      <td>add support translat expess from_str to_str c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5423</td>\n",
       "      <td>extend simplifi reduc express would like cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5424</td>\n",
       "      <td>add support timestampadd timestampdiff functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7939</th>\n",
       "      <td>13359</td>\n",
       "      <td>improve frameobject tostring output currently ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>13360</td>\n",
       "      <td>add vector as supported type in frame conversi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7941</th>\n",
       "      <td>13361</td>\n",
       "      <td>performance: improve vector dataframe conversi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7942</th>\n",
       "      <td>13362</td>\n",
       "      <td>performance: improve vector dataframe conversi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7943</th>\n",
       "      <td>13363</td>\n",
       "      <td>performance: improve vector dataframe conversi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7944 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                               Text\n",
       "0      5420   allow sqloper overridden valid calcit allow f...\n",
       "1      5421   allow sqloper overridden valid calcit allow f...\n",
       "2      5422   add support translat expess from_str to_str c...\n",
       "3      5423   extend simplifi reduc express would like cove...\n",
       "4      5424   add support timestampadd timestampdiff functi...\n",
       "...     ...                                                ...\n",
       "7939  13359  improve frameobject tostring output currently ...\n",
       "7940  13360  add vector as supported type in frame conversi...\n",
       "7941  13361  performance: improve vector dataframe conversi...\n",
       "7942  13362  performance: improve vector dataframe conversi...\n",
       "7943  13363  performance: improve vector dataframe conversi...\n",
       "\n",
       "[7944 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Importing preprocessed dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "tag = pd.read_csv(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/dataset/Tag.csv\")\n",
    "data = pd.read_csv(\"/Users/kritya/DSCI_Project/project-dsci-644-group-7-dsci_7/src/dataset/TextPreprocessed.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5420</td>\n",
       "      <td>extract method                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5421</td>\n",
       "      <td>rename method                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5422</td>\n",
       "      <td>extract method                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5423</td>\n",
       "      <td>extract method                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5424</td>\n",
       "      <td>move attribute                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13131</th>\n",
       "      <td>18551</td>\n",
       "      <td>extract method                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13132</th>\n",
       "      <td>18552</td>\n",
       "      <td>rename method                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13133</th>\n",
       "      <td>18553</td>\n",
       "      <td>extract method                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13134</th>\n",
       "      <td>18554</td>\n",
       "      <td>move attribute                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13135</th>\n",
       "      <td>18555</td>\n",
       "      <td>rename method                                 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13136 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id                                                Tag\n",
       "0       5420  extract method                                ...\n",
       "1       5421  rename method                                 ...\n",
       "2       5422  extract method                                ...\n",
       "3       5423  extract method                                ...\n",
       "4       5424  move attribute                                ...\n",
       "...      ...                                                ...\n",
       "13131  18551  extract method                                ...\n",
       "13132  18552  rename method                                 ...\n",
       "13133  18553  extract method                                ...\n",
       "13134  18554  move attribute                                ...\n",
       "13135  18555  rename method                                 ...\n",
       "\n",
       "[13136 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5420</td>\n",
       "      <td>extract method                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5421</td>\n",
       "      <td>rename method                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5422</td>\n",
       "      <td>extract method                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5423</td>\n",
       "      <td>extract method                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5424</td>\n",
       "      <td>move attribute                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7939</th>\n",
       "      <td>13359</td>\n",
       "      <td>rename method                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>13360</td>\n",
       "      <td>extract method                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7941</th>\n",
       "      <td>13361</td>\n",
       "      <td>rename class                                  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7942</th>\n",
       "      <td>13362</td>\n",
       "      <td>rename method                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7943</th>\n",
       "      <td>13363</td>\n",
       "      <td>move method                                   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7944 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                                Tag\n",
       "0      5420  extract method                                ...\n",
       "1      5421  rename method                                 ...\n",
       "2      5422  extract method                                ...\n",
       "3      5423  extract method                                ...\n",
       "4      5424  move attribute                                ...\n",
       "...     ...                                                ...\n",
       "7939  13359  rename method                                 ...\n",
       "7940  13360  extract method                                ...\n",
       "7941  13361  rename class                                  ...\n",
       "7942  13362  rename method                                 ...\n",
       "7943  13363  move method                                   ...\n",
       "\n",
       "[7944 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = tag.head(7944)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(label['Tag'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: \n",
      "(5560,)\n",
      "(5560,)\n",
      "Shape of test data: \n",
      "(2384,)\n",
      "(2384,)\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"Text\"], label[\"Tag\"], test_size=0.30, random_state=42)\n",
    "\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "max_words = len(X_train[1])\n",
    "# Create a tokenizer object\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "# Fit the tokenizer on the training data\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "words_to_index = tokenizer.word_index\n",
    "vocab_len = len(words_to_index)+1\n",
    "embed_vector_len = 128\n",
    "maxLen = 4484 #Maximum review length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "# Convert the text data to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_words)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_words)\n",
    "\n",
    "# create an instance of the LabelEncoder class\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fit the encoder to the labels and transform them to numerical values\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# create an instance of the OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# fit the encoder on y_train and transform y_train and y_test\n",
    "y_train_one_hot = encoder.fit_transform(y_train_encoded.reshape(-1, 1))\n",
    "y_test_one_hot = encoder.transform(y_test_encoded.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "174/174 [==============================] - 12s 62ms/step - loss: 2.0618 - accuracy: 0.3167\n",
      "Epoch 2/20\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 2.0254 - accuracy: 0.3227\n",
      "Epoch 3/20\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 1.9908 - accuracy: 0.3353\n",
      "Epoch 4/20\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 1.9089 - accuracy: 0.3651\n",
      "Epoch 5/20\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.7777 - accuracy: 0.4018\n",
      "Epoch 6/20\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.6413 - accuracy: 0.4491\n",
      "Epoch 7/20\n",
      "174/174 [==============================] - 10s 59ms/step - loss: 1.5051 - accuracy: 0.4844\n",
      "Epoch 8/20\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 1.3727 - accuracy: 0.5362\n",
      "Epoch 9/20\n",
      "174/174 [==============================] - 11s 63ms/step - loss: 1.2668 - accuracy: 0.5727\n",
      "Epoch 10/20\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 1.1736 - accuracy: 0.5957\n",
      "Epoch 11/20\n",
      "174/174 [==============================] - 10s 59ms/step - loss: 1.0977 - accuracy: 0.6237\n",
      "Epoch 12/20\n",
      "174/174 [==============================] - 10s 58ms/step - loss: 1.0346 - accuracy: 0.6362\n",
      "Epoch 13/20\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 0.9642 - accuracy: 0.6604\n",
      "Epoch 14/20\n",
      "174/174 [==============================] - 11s 62ms/step - loss: 0.9223 - accuracy: 0.6622\n",
      "Epoch 15/20\n",
      "174/174 [==============================] - 11s 61ms/step - loss: 0.8763 - accuracy: 0.6831\n",
      "Epoch 16/20\n",
      "174/174 [==============================] - 11s 65ms/step - loss: 0.8392 - accuracy: 0.6835\n",
      "Epoch 17/20\n",
      "174/174 [==============================] - 11s 63ms/step - loss: 0.8114 - accuracy: 0.6910\n",
      "Epoch 18/20\n",
      "174/174 [==============================] - 11s 66ms/step - loss: 0.7808 - accuracy: 0.7007\n",
      "Epoch 19/20\n",
      "174/174 [==============================] - 11s 63ms/step - loss: 0.7562 - accuracy: 0.7052\n",
      "Epoch 20/20\n",
      "174/174 [==============================] - 10s 60ms/step - loss: 0.7493 - accuracy: 0.7047\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=max_words, trainable=True)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=max_words, trainable=True),\n",
    "    layers.Conv1D(32, 3, activation='relu', padding='same'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(14, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_pad, y_train_encoded, batch_size=32, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 13,  7, ...,  1,  5,  1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Converting type of columns to category\n",
    "y_test = y_test.astype('category')\n",
    "\n",
    "tag = y_test.cat.codes\n",
    "\n",
    "# Reshape tag to have one column\n",
    "tag = tag.values.reshape(-1, 1)\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "# Fit and transform the encoded columns\n",
    "enc_data = enc.fit_transform(tag).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'subset_accuracy' from 'sklearn.metrics' (/Users/kritya/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-db846f6951ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhamming_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'subset_accuracy' from 'sklearn.metrics' (/Users/kritya/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def subset_accuracy(y_true, y_pred):\n",
    "    print('Subset accuracy: {0}'.format(sklearn.metrics.accuracy_score(y_true, y_pred, normalize=True, sample_weight=None)))\n",
    "\n",
    "def hamming_loss(y_true, y_pred):\n",
    "    print('Hamming loss: {0}'.format(sklearn.metrics.hamming_loss(y_true, y_pred)))\n",
    "\n",
    "def hamming_score(y_true, y_pred):\n",
    "    print('Hamming score: {0}'.format(hamming_score(y_true, y_pred)))\n",
    "\n",
    "\n",
    "y_true = y_test_one_hot\n",
    "\n",
    "y_pred = model.predict(X_test_pad)\n",
    "threshold = 0.5\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "y_pred = y_pred_binary\n",
    "y_true = preprocessing.label_binarize(y_test, classes=np.unique(y_test))\n",
    "\n",
    "subset_accuracy(y_true, y_pred)\n",
    "hamming_loss(y_true, y_pred)\n",
    "hamming_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 10ms/step\n",
      "Confusion Matrix:\n",
      "[[[2344    6]\n",
      "  [  34    0]]\n",
      "\n",
      " [[1219  376]\n",
      "  [ 585  204]]\n",
      "\n",
      " [[2351    8]\n",
      "  [  25    0]]\n",
      "\n",
      " [[2140   94]\n",
      "  [ 145    5]]\n",
      "\n",
      " [[2321   14]\n",
      "  [  49    0]]\n",
      "\n",
      " [[2151   48]\n",
      "  [ 184    1]]\n",
      "\n",
      " [[2232   39]\n",
      "  [ 110    3]]\n",
      "\n",
      " [[1991  134]\n",
      "  [ 251    8]]\n",
      "\n",
      " [[2335   13]\n",
      "  [  35    1]]\n",
      "\n",
      " [[2329   10]\n",
      "  [  45    0]]\n",
      "\n",
      " [[2358    2]\n",
      "  [  24    0]]\n",
      "\n",
      " [[2351    5]\n",
      "  [  28    0]]\n",
      "\n",
      " [[2142   90]\n",
      "  [ 144    8]]\n",
      "\n",
      " [[1558  331]\n",
      "  [ 420   75]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "y_true = y_test_one_hot\n",
    "\n",
    "y_pred = model.predict(X_test_pad)\n",
    "threshold = 0.5\n",
    "y_true = preprocessing.label_binarize(y_test, classes=np.unique(y_test))\n",
    "y_pred_binary = np.where(y_pred > threshold, 1, 0)\n",
    "y_pred = y_pred_binary\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "confusion_matrix = multilabel_confusion_matrix(y_true, y_pred)\n",
    "print(multilabel_confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming score: 0.9026546021093\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "total_labels = 0\n",
    "\n",
    "for i in range(14):\n",
    "    cm = confusion_matrix[i]\n",
    "    correct = np.sum(np.diag(cm))\n",
    "    total_correct += correct\n",
    "    total_labels += np.sum(cm)\n",
    "\n",
    "hamming_score = total_correct / total_labels\n",
    "print('Hamming score: {0}'.format(hamming_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
